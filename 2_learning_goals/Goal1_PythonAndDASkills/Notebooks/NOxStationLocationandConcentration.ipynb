{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97350872-005c-4579-991a-b7622bb2d552",
   "metadata": {},
   "source": [
    "**RIVM NO$_x$ measurements couple with station location**\n",
    "\n",
    "In this notebook, I plotted NO$_x$ measurements across the Netherlands. I began by identifying the dataset's temporal and spatial details, ensuring it included values, timestamps, and station identifiers. I focused on stations with data from both 2019 and 2023 by comparing station IDs or names between the two years. I defined day and night intervals (day: 6 AM–7 PM, night: 7 PM–6 AM) and calculated average NO$_x$ values for 2019 day, 2019 night, 2023 day, and 2023 night. Optionally, I computed averages for weekdays if time allowed. I matched stations with latitude and longitude data, enriching the dataset if necessary. \n",
    "\n",
    "Finally, I prepared the data for import into ArcGIS Pro by converting it to an Excel file. \n",
    "\n",
    "I loaded the data into ArcGIS Pro, applied appropriate symbology to visualize NO$_x$ levels. (Not included in this notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1586d51-81f9-403b-b109-7e76d901649e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import DataFrame\n",
    "from pandas import Grouper\n",
    "from pandas import read_csv\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b7d7676c-1e26-454c-aada-894edd0e7084",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from shapely.geometry import Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29bfe726-8a3f-4359-aa99-8a7d62a6c0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a excel file with all NOx measurements stations and average concentrations.\n",
    "# Read the files, NOx 2019, NOx 2023, station info,\n",
    "NOx_2019=pd.read_csv(\"/Data/2019_NOx_breed.csv\",sep=';',skiprows=5,encoding='unicode_escape')#read 2019 file\n",
    "NOx_2023=pd.read_csv(\"/Data/2023_NOx_breed.csv\",sep=';',skiprows=5,encoding='unicode_escape')#read 2023 files\n",
    "Station_info=pd.read_csv(\"/Data/RIVM_StationLocations.csv\",sep=';',skiprows=5,encoding='unicode_escape')#read location information file\n",
    "\n",
    "# Edit the column name \" begindatumtijd\" to \"begindatumtijd\", change it to \"datetime\" format \n",
    "# Strip spaces from all column names\n",
    "NOx_2019.columns = NOx_2019.columns.str.strip()\n",
    "NOx_2023.columns = NOx_2023.columns.str.strip()\n",
    "NOx_2019['begindatumtijd'] = pd.to_datetime(NOx_2019['begindatumtijd'], format='%Y-%m-%dT%H:%M:%S%z')\n",
    "NOx_2019['begindatumtijd'] = pd.to_datetime(NOx_2019['begindatumtijd']).dt.tz_localize(None)\n",
    "NOx_2023['begindatumtijd'] = pd.to_datetime(NOx_2023['begindatumtijd'], format='%Y-%m-%dT%H:%M:%S%z')\n",
    "NOx_2023['begindatumtijd'] = pd.to_datetime(NOx_2023['begindatumtijd']).dt.tz_localize(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56543822-638f-42cf-a462-3ec4a59bc329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the period of October for each NOx datasets (month number 10)\n",
    "NOx_2019_Oct = NOx_2019[NOx_2019['begindatumtijd'].dt.month == 10]\n",
    "NOx_2023_Oct = NOx_2023[NOx_2023['begindatumtijd'].dt.month == 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6436738-159a-4aad-82ae-7c4d39420948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of October 2019 dataset:\n",
      "\n",
      "Initial number of columns: 91\n",
      "Columns removed: 6\n",
      "Remaining columns: 85\n",
      "\n",
      "Removed columns and their NaN counts:\n",
      "- NL01485_NOx_lucht: 744 NaN values\n",
      "- NL01491_NOx_lucht.1: 744 NaN values\n",
      "- NL01494_NOx_lucht: 217 NaN values\n",
      "- NL01494_NOx_lucht.1: 531 NaN values\n",
      "- NL10246_NOx_lucht: 313 NaN values\n",
      "- NL49019_NOx_lucht: 72 NaN values\n",
      "\n",
      "Percentage of columns retained: 93.4%\n",
      "\n",
      "Analysis of October 2023 dataset:\n",
      "\n",
      "Initial number of columns: 91\n",
      "Columns removed: 5\n",
      "Remaining columns: 86\n",
      "\n",
      "Removed columns and their NaN counts:\n",
      "- NL01493_NOx_lucht.1: 744 NaN values\n",
      "- NL01497_NOx_lucht.1: 744 NaN values\n",
      "- NL10633_NOx_lucht: 81 NaN values\n",
      "- NL10807_NOx_lucht.1: 744 NaN values\n",
      "- NL10929_NOx_lucht: 85 NaN values\n",
      "\n",
      "Percentage of columns retained: 94.5%\n"
     ]
    }
   ],
   "source": [
    "# Remove columns with more than 50 NaN values, so only almost complete measurements are there.\n",
    "def remove_columns_with_many_nans(df, threshold=10, verbose=True):\n",
    "    # Initial column count\n",
    "    initial_columns = len(df.columns)\n",
    "    \n",
    "    # Count NaN values in each column\n",
    "    nan_counts = df.isna().sum()\n",
    "    \n",
    "    # Get columns to drop\n",
    "    columns_to_drop = nan_counts[nan_counts > threshold].index.tolist()\n",
    "    \n",
    "    # Remove these columns\n",
    "    df_cleaned = df.drop(columns=columns_to_drop)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"\\nInitial number of columns: {initial_columns}\")\n",
    "        print(f\"Columns removed: {len(columns_to_drop)}\")\n",
    "        print(f\"Remaining columns: {len(df_cleaned.columns)}\")\n",
    "        \n",
    "        if columns_to_drop:\n",
    "            print(\"\\nRemoved columns and their NaN counts:\")\n",
    "            for col in columns_to_drop:\n",
    "                print(f\"- {col}: {nan_counts[col]} NaN values\")\n",
    "                \n",
    "        print(\"\\nPercentage of columns retained: {:.1f}%\".format(\n",
    "            (len(df_cleaned.columns) / initial_columns) * 100))\n",
    "    \n",
    "    return df_cleaned\n",
    "\n",
    "# Apply the function to both datasets\n",
    "print(\"Analysis of October 2019 dataset:\")\n",
    "NOx_2019_Oct_cleaned = remove_columns_with_many_nans(NOx_2019_Oct, threshold=50)\n",
    "\n",
    "print(\"\\nAnalysis of October 2023 dataset:\")\n",
    "NOx_2023_Oct_cleaned = remove_columns_with_many_nans(NOx_2023_Oct, threshold=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b22724fb-363a-44ec-a1ab-4d38dc2fa573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common columns in both datasets (78):\n",
      "['NL01487_NOx_lucht', 'NL01488_NOx_lucht', 'NL01489_NOx_lucht', 'NL01491_NOx_lucht', 'NL01493_NOx_lucht', 'NL01495_NOx_lucht', 'NL01496_NOx_lucht', 'NL01912_NOx_lucht', 'NL10107_NOx_lucht', 'NL10131_NOx_lucht', 'NL10133_NOx_lucht', 'NL10136_NOx_lucht', 'NL10138_NOx_lucht', 'NL10230_NOx_lucht', 'NL10235_NOx_lucht', 'NL10236_NOx_lucht', 'NL10237_NOx_lucht', 'NL10240_NOx_lucht', 'NL10241_NOx_lucht', 'NL10247_NOx_lucht', 'NL10301_NOx_lucht', 'NL10318_NOx_lucht', 'NL10404_NOx_lucht', 'NL10418_NOx_lucht', 'NL10437_NOx_lucht', 'NL10442_NOx_lucht', 'NL10444_NOx_lucht', 'NL10445_NOx_lucht', 'NL10446_NOx_lucht', 'NL10449_NOx_lucht', 'NL10538_NOx_lucht', 'NL10550_NOx_lucht', 'NL10617_NOx_lucht', 'NL10636_NOx_lucht', 'NL10639_NOx_lucht', 'NL10641_NOx_lucht', 'NL10643_NOx_lucht', 'NL10644_NOx_lucht', 'NL10722_NOx_lucht', 'NL10738_NOx_lucht', 'NL10741_NOx_lucht', 'NL10742_NOx_lucht', 'NL10807_NOx_lucht', 'NL10818_NOx_lucht', 'NL10918_NOx_lucht', 'NL10934_NOx_lucht', 'NL10937_NOx_lucht', 'NL10938_NOx_lucht', 'NL49002_NOx_lucht', 'NL49003_NOx_lucht', 'NL49007_NOx_lucht', 'NL49012_NOx_lucht', 'NL49014_NOx_lucht', 'NL49017_NOx_lucht', 'NL49020_NOx_lucht', 'NL49021_NOx_lucht', 'NL49022_NOx_lucht', 'NL49546_NOx_lucht', 'NL49551_NOx_lucht', 'NL49553_NOx_lucht', 'NL49561_NOx_lucht', 'NL49564_NOx_lucht', 'NL49565_NOx_lucht', 'NL49701_NOx_lucht', 'NL49703_NOx_lucht', 'NL49704_NOx_lucht', 'NL53001_NOx_lucht', 'NL53004_NOx_lucht', 'NL53015_NOx_lucht', 'NL53016_NOx_lucht', 'NL53020_NOx_lucht', 'NL54004_NOx_lucht', 'begindatumtijd', 'component', 'eenheid', 'einddatumtijd', 'matrix', 'meetduur']\n",
      "\n",
      "Columns unique to 2019 (7):\n",
      "['NL01485_NOx_lucht.1', 'NL01908_NOx_lucht', 'NL10633_NOx_lucht', 'NL10929_NOx_lucht', 'NL50002_NOx_lucht', 'NL50003_NOx_lucht', 'NL50004_NOx_lucht']\n",
      "\n",
      "Columns unique to 2023 (8):\n",
      "['NL01485_NOx_lucht', 'NL01494_NOx_lucht', 'NL01497_NOx_lucht', 'NL01913_NOx_lucht', 'NL10246_NOx_lucht', 'NL10248_NOx_lucht', 'NL10450_NOx_lucht', 'NL49019_NOx_lucht']\n",
      "\n",
      "Summary:\n",
      "Total columns in 2019: 85\n",
      "Total columns in 2023: 86\n",
      "Common columns: 78\n"
     ]
    }
   ],
   "source": [
    "# Find the stations that exist in both datasets, and exclude stations that do not have measurements at both years.\n",
    "# Define a function to compare column sets.\n",
    "def compare_column_sets(df1, df2, name1='Dataset 1', name2='Dataset 2', verbose=True):\n",
    "    \"\"\"\n",
    "    Compare columns between two dataframes and identify common and unique columns.\n",
    "    \n",
    "    Parameters:\n",
    "    df1 (DataFrame): First DataFrame\n",
    "    df2 (DataFrame): Second DataFrame\n",
    "    name1 (str): Name of first DataFrame for output\n",
    "    name2 (str): Name of second DataFrame for output\n",
    "    verbose (bool): If True, prints the results\n",
    "    \n",
    "    Returns:\n",
    "    dict: Dictionary containing common and unique columns\n",
    "    \"\"\"\n",
    "     # Convert columns to sets\n",
    "    columns1 = set(df1.columns)\n",
    "    columns2 = set(df2.columns)\n",
    "    \n",
    "    # Find common and unique columns\n",
    "    common_columns = columns1.intersection(columns2)\n",
    "    unique_to_df1 = columns1 - columns2\n",
    "    unique_to_df2 = columns2 - columns1\n",
    "    \n",
    "    # Store results in a dictionary\n",
    "    results = {\n",
    "        'common_columns': sorted(list(common_columns)),\n",
    "        f'unique_to_{name1}': sorted(list(unique_to_df1)),\n",
    "        f'unique_to_{name2}': sorted(list(unique_to_df2))\n",
    "    }\n",
    "    \n",
    "    # Print results if verbose is True\n",
    "    if verbose:\n",
    "        print(f\"Common columns in both datasets ({len(common_columns)}):\")\n",
    "        print(results['common_columns'])\n",
    "        print(f\"\\nColumns unique to {name1} ({len(unique_to_df1)}):\")\n",
    "        print(results[f'unique_to_{name1}'])\n",
    "        print(f\"\\nColumns unique to {name2} ({len(unique_to_df2)}):\")\n",
    "        print(results[f'unique_to_{name2}'])\n",
    "        \n",
    "        # Print summary statistics\n",
    "        print(f\"\\nSummary:\")\n",
    "        print(f\"Total columns in {name1}: {len(columns1)}\")\n",
    "        print(f\"Total columns in {name2}: {len(columns2)}\")\n",
    "        print(f\"Common columns: {len(common_columns)}\")\n",
    "        \n",
    "    return results\n",
    "# Get the list of column names from both DataFrames\n",
    "results = compare_column_sets(\n",
    "    NOx_2019_Oct_cleaned, \n",
    "    NOx_2023_Oct_cleaned,\n",
    "    name1='2019',\n",
    "    name2='2023'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0b998d7-cb27-4c29-91ee-fb870df21bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common columns in both datasets (79):\n",
      "['NL01485_NOx_lucht', 'NL01487_NOx_lucht', 'NL01488_NOx_lucht', 'NL01489_NOx_lucht', 'NL01491_NOx_lucht', 'NL01493_NOx_lucht', 'NL01495_NOx_lucht', 'NL01496_NOx_lucht', 'NL01912_NOx_lucht', 'NL10107_NOx_lucht', 'NL10131_NOx_lucht', 'NL10133_NOx_lucht', 'NL10136_NOx_lucht', 'NL10138_NOx_lucht', 'NL10230_NOx_lucht', 'NL10235_NOx_lucht', 'NL10236_NOx_lucht', 'NL10237_NOx_lucht', 'NL10240_NOx_lucht', 'NL10241_NOx_lucht', 'NL10247_NOx_lucht', 'NL10301_NOx_lucht', 'NL10318_NOx_lucht', 'NL10404_NOx_lucht', 'NL10418_NOx_lucht', 'NL10437_NOx_lucht', 'NL10442_NOx_lucht', 'NL10444_NOx_lucht', 'NL10445_NOx_lucht', 'NL10446_NOx_lucht', 'NL10449_NOx_lucht', 'NL10538_NOx_lucht', 'NL10550_NOx_lucht', 'NL10617_NOx_lucht', 'NL10636_NOx_lucht', 'NL10639_NOx_lucht', 'NL10641_NOx_lucht', 'NL10643_NOx_lucht', 'NL10644_NOx_lucht', 'NL10722_NOx_lucht', 'NL10738_NOx_lucht', 'NL10741_NOx_lucht', 'NL10742_NOx_lucht', 'NL10807_NOx_lucht', 'NL10818_NOx_lucht', 'NL10918_NOx_lucht', 'NL10934_NOx_lucht', 'NL10937_NOx_lucht', 'NL10938_NOx_lucht', 'NL49002_NOx_lucht', 'NL49003_NOx_lucht', 'NL49007_NOx_lucht', 'NL49012_NOx_lucht', 'NL49014_NOx_lucht', 'NL49017_NOx_lucht', 'NL49020_NOx_lucht', 'NL49021_NOx_lucht', 'NL49022_NOx_lucht', 'NL49546_NOx_lucht', 'NL49551_NOx_lucht', 'NL49553_NOx_lucht', 'NL49561_NOx_lucht', 'NL49564_NOx_lucht', 'NL49565_NOx_lucht', 'NL49701_NOx_lucht', 'NL49703_NOx_lucht', 'NL49704_NOx_lucht', 'NL53001_NOx_lucht', 'NL53004_NOx_lucht', 'NL53015_NOx_lucht', 'NL53016_NOx_lucht', 'NL53020_NOx_lucht', 'NL54004_NOx_lucht', 'begindatumtijd', 'component', 'eenheid', 'einddatumtijd', 'matrix', 'meetduur']\n",
      "\n",
      "Columns unique to 2019 (6):\n",
      "['NL01908_NOx_lucht', 'NL10633_NOx_lucht', 'NL10929_NOx_lucht', 'NL50002_NOx_lucht', 'NL50003_NOx_lucht', 'NL50004_NOx_lucht']\n",
      "\n",
      "Columns unique to 2023 (7):\n",
      "['NL01494_NOx_lucht', 'NL01497_NOx_lucht', 'NL01913_NOx_lucht', 'NL10246_NOx_lucht', 'NL10248_NOx_lucht', 'NL10450_NOx_lucht', 'NL49019_NOx_lucht']\n",
      "\n",
      "Summary:\n",
      "Total columns in 2019: 85\n",
      "Total columns in 2023: 86\n",
      "Common columns: 79\n"
     ]
    }
   ],
   "source": [
    "# The column NL01485_NOx_lucht.1 in 2019 dataset can be renamed and is the same as \"NL01485_NOx_lucht\" in 2023.\n",
    "NOx_2019_Oct_cleaned = NOx_2019_Oct_cleaned.rename(columns={'NL01485_NOx_lucht.1': 'NL01485_NOx_lucht'})\n",
    "\n",
    "# Use the function again and delete unique station measurements.\n",
    "results_new = compare_column_sets(\n",
    "    NOx_2019_Oct_cleaned, \n",
    "    NOx_2023_Oct_cleaned,\n",
    "    name1='2019',\n",
    "    name2='2023'\n",
    ")\n",
    "\n",
    "# Get common columns from the results dictionary\n",
    "common_columns = results_new['common_columns']\n",
    "\n",
    "# Create new datasets with only common columns\n",
    "NOx_2019_Oct_Updated = NOx_2019_Oct_cleaned[common_columns].copy()\n",
    "NOx_2023_Oct_Updated = NOx_2023_Oct_cleaned[common_columns].copy()\n",
    "\n",
    "# Remove '_NOx_lucht' from column names\n",
    "NOx_2019_Oct_Updated.columns = [col.replace('_NOx_lucht', '') for col in NOx_2019_Oct_Updated.columns]\n",
    "NOx_2023_Oct_Updated.columns = [col.replace('_NOx_lucht', '') for col in NOx_2023_Oct_Updated.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80aae80d-0da7-4dd5-91c6-c86ae0873933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete columns \"component eenheid einddatumtijd matrix meetduur\", and set \"begindatumtijd\" as the key.\n",
    "# List of columns to remove\n",
    "columns_to_remove = ['component', 'eenheid', 'einddatumtijd', 'matrix', 'meetduur']\n",
    "\n",
    "# Remove specified columns from 2019 dataset\n",
    "NOx_2019_Oct_Updated = NOx_2019_Oct_Updated.drop(columns=columns_to_remove, errors='ignore')\n",
    "# Set begindatumtijd as index for 2019\n",
    "NOx_2019_Oct_Updated.set_index('begindatumtijd', inplace=True)\n",
    "\n",
    "# Remove specified columns from 2023 dataset\n",
    "NOx_2023_Oct_Updated = NOx_2023_Oct_Updated.drop(columns=columns_to_remove, errors='ignore')\n",
    "# Set begindatumtijd as index for 2023\n",
    "NOx_2023_Oct_Updated.set_index('begindatumtijd', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "610cefe2-8195-4f92-afca-9f72b1f75641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for all stations:\n",
      "         Day_Ave_19  Nig_Ave_19  Day_Ave_23  Nig_Ave_20\n",
      "NL01485   38.571596   28.402539   26.934156   20.122554\n",
      "NL01487   89.011058   51.032610   59.986052   42.083053\n",
      "NL01488   32.655757   25.596422   21.975444   19.552525\n",
      "NL01489   60.724712   38.006628   39.580769   27.988258\n",
      "NL01491   54.671077   37.229390   42.920412   34.651493\n",
      "...             ...         ...         ...         ...\n",
      "NL53004   29.759102   27.106745   36.018481   41.520882\n",
      "NL53015   22.370426   17.693030   38.747558   45.635484\n",
      "NL53016   24.175000   18.535758   14.304859   12.175367\n",
      "NL53020   23.997215   20.907038   19.592072   16.007122\n",
      "NL54004   58.437221   31.377067   37.438246   26.031601\n",
      "\n",
      "[73 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Calculate the average for night and day (Oct 2019 day, Oct 2019 night, Oct 2023 day, Oct 2023 night, extra time: weekdays?).\n",
    "# 2019 Calculations\n",
    "# Create hour column\n",
    "NOx_2019_Oct_Updated['hour'] = NOx_2019_Oct_Updated.index.hour\n",
    "\n",
    "# Calculate day averages (6-19)\n",
    "day_mask_2019 = (NOx_2019_Oct_Updated['hour'] >= 6) & (NOx_2019_Oct_Updated['hour'] < 19)\n",
    "day_avg_2019 = NOx_2019_Oct_Updated[day_mask_2019].drop('hour', axis=1).mean()\n",
    "\n",
    "# Calculate night averages (19-6)\n",
    "night_mask_2019 = (NOx_2019_Oct_Updated['hour'] >= 19) | (NOx_2019_Oct_Updated['hour'] < 6)\n",
    "night_avg_2019 = NOx_2019_Oct_Updated[night_mask_2019].drop('hour', axis=1).mean()\n",
    "\n",
    "# 2023 Calculations\n",
    "# Create hour column\n",
    "NOx_2023_Oct_Updated['hour'] = NOx_2023_Oct_Updated.index.hour\n",
    "\n",
    "# Calculate day averages (6-19)\n",
    "day_mask_2023 = (NOx_2023_Oct_Updated['hour'] >= 6) & (NOx_2023_Oct_Updated['hour'] < 19)\n",
    "day_avg_2023 = NOx_2023_Oct_Updated[day_mask_2023].drop('hour', axis=1).mean()\n",
    "\n",
    "# Calculate night averages (19-6)\n",
    "night_mask_2023 = (NOx_2023_Oct_Updated['hour'] >= 19) | (NOx_2023_Oct_Updated['hour'] < 6)\n",
    "night_avg_2023 = NOx_2023_Oct_Updated[night_mask_2023].drop('hour', axis=1).mean()\n",
    "\n",
    "# Create a new table containing stations with average concentration in 2019 and 2023.\n",
    "\n",
    "# Create results DataFrame\n",
    "NOx_Average = pd.DataFrame({\n",
    "    'Day_Ave_19': day_avg_2019,\n",
    "    'Nig_Ave_19': night_avg_2019,\n",
    "    'Day_Ave_23': day_avg_2023,\n",
    "    'Nig_Ave_20': night_avg_2023\n",
    "})\n",
    "\n",
    "# Print results\n",
    "print(\"Results for all stations:\")\n",
    "print(NOx_Average)\n",
    "\n",
    "# Clean up by dropping the hour columns we created\n",
    "NOx_2019_Oct_Updated.drop('hour', axis=1, inplace=True)\n",
    "NOx_2023_Oct_Updated.drop('hour', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4ce3983d-766b-41a1-a100-966af13206bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect stations with lat and lon \n",
    "# Select and rename columns\n",
    "Station_Lat_Lon = Station_info[['meetlocatie_id', 'breedtegraad', 'lengtegraad']].rename(\n",
    "    columns={\n",
    "        'meetlocatie_id': 'ID',\n",
    "        'breedtegraad': 'Latitude',\n",
    "        'lengtegraad': 'Longitude'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "90c0d35a-7eb0-4ac9-8490-a543246454c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of joined dataframe: (73, 6)\n",
      "\n",
      "Columns: ['Day_Ave_19', 'Nig_Ave_19', 'Day_Ave_23', 'Nig_Ave_20', 'Latitude', 'Longitude']\n",
      "\n",
      "Sample of joined data:\n",
      "         Day_Ave_19  Nig_Ave_19  Day_Ave_23  Nig_Ave_20   Latitude  Longitude\n",
      "NL01485   38.571596   28.402539   26.934156   20.122554  51.867411   4.355242\n",
      "NL01487   89.011058   51.032610   59.986052   42.083053  51.891147   4.480690\n",
      "NL01488   32.655757   25.596422   21.975444   19.552525  51.893617   4.487528\n",
      "NL01489   60.724712   38.006628   39.580769   27.988258  51.869431   4.580058\n",
      "NL01491   54.671077   37.229390   42.920412   34.651493  51.938472   4.430692\n"
     ]
    }
   ],
   "source": [
    "# Set 'ID' as index for Station_Lat_Lon\n",
    "Station_Lat_Lon = Station_Lat_Lon.set_index('ID')\n",
    "\n",
    "# Perform inner join using merge\n",
    "NOx_Average_with_Location = pd.merge(\n",
    "    NOx_Average, \n",
    "    Station_Lat_Lon, \n",
    "    left_index=True, \n",
    "    right_index=True, \n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# Print results to verify\n",
    "print(\"Shape of joined dataframe:\", NOx_Average_with_Location.shape)\n",
    "print(\"\\nColumns:\", NOx_Average_with_Location.columns.tolist())\n",
    "print(\"\\nSample of joined data:\")\n",
    "print(NOx_Average_with_Location.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1817f403-9513-458e-8bd4-2686b6c70a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic way to save to Excel\n",
    "NOx_Average_with_Location.to_excel('/Users/zhiyuwu/Desktop/GRS-35306/GroupProject/Data/NOx_Average_with_Location.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
